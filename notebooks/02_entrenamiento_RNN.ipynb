{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de RNN Básica para Análisis de Sentimiento en Tweets\n",
    "\n",
    "Este notebook implementa y entrena una Red Neuronal Recurrente (RNN) básica para clasificar tweets según su sentimiento (positivo o negativo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración Inicial e Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadir directorio de nivel superior al path para poder importar módulos del proyecto\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from src.utils import clean_text, plot_history, evaluate_model, plot_class_distribution\n",
    "from src.data_loader import load_data, prepare_data, get_class_weights\n",
    "from src.model_rnn import create_rnn_model\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(style=\"whitegrid\", palette=\"deep\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configurar memoria de GPU (si está disponible)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs disponibles: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Parámetros\n",
    "MAX_WORDS = 10000  # Tamaño máximo del vocabulario\n",
    "MAX_LEN = 100      # Longitud máxima de las secuencias\n",
    "TEST_SIZE = 0.2    # Proporción para conjunto de prueba\n",
    "RANDOM_STATE = 42  # Semilla para reproducibilidad\n",
    "BATCH_SIZE = 128   # Tamaño del batch para entrenamiento\n",
    "EPOCHS = 5         # Número de épocas de entrenamiento\n",
    "\n",
    "# Estrategia para el desbalanceo de clases\n",
    "# Opciones: None, 'oversampling', 'smote', 'class_weights'\n",
    "BALANCE_STRATEGY = 'oversampling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargar datos\n",
    "df = load_data(balance_method='oversampling' if BALANCE_STRATEGY == 'oversampling' else None)\n",
    "\n",
    "# Mostrar la distribución de clases\n",
    "plot_class_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preparar datos para entrenamiento\n",
    "X_train, X_test, y_train, y_test, tokenizer = prepare_data(\n",
    "    df, \n",
    "    max_words=MAX_WORDS, \n",
    "    max_len=MAX_LEN, \n",
    "    test_size=TEST_SIZE, \n",
    "    balance_method='smote' if BALANCE_STRATEGY == 'smote' else None,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Información sobre los datos preparados\n",
    "print(f\"Tamaño del vocabulario: {min(len(tokenizer.word_index) + 1, MAX_WORDS)}\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construcción y Compilación del Modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Parámetros del modelo\n",
    "VOCAB_SIZE = min(len(tokenizer.word_index) + 1, MAX_WORDS)\n",
    "EMBEDDING_DIM = 64   # Dimensión de los embeddings\n",
    "RNN_UNITS = 64       # Número de unidades en la capa RNN\n",
    "DROPOUT_RATE = 0.3   # Tasa de dropout para regularización\n",
    "\n",
    "# Crear modelo RNN\n",
    "model = create_rnn_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_units=RNN_UNITS,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ")\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definir callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(\n",
    "        filepath='../models/rnn_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Calcular class weights si es necesario\n",
    "class_weights = get_class_weights(y_train) if BALANCE_STRATEGY == 'class_weights' else None\n",
    "if BALANCE_STRATEGY == 'class_weights':\n",
    "    print(\"Pesos de clase:\", class_weights)\n",
    "\n",
    "# Entrenar modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Graficar métricas de entrenamiento\n",
    "plot_history(history, title=\"Métricas de Entrenamiento - RNN Básica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluar en conjunto de prueba\n",
    "metrics = evaluate_model(model, X_test, y_test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Obtener reporte de clasificación detallado\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "print(classification_report(y_test, y_pred, target_names=['Negativo', 'Positivo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardar Modelo y Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Crear directorio para modelos si no existe\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Guardar modelo\n",
    "model_path = '../models/rnn_model.h5'\n",
    "model.save(model_path)\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "\n",
    "# Guardar tokenizer\n",
    "tokenizer_path = '../models/rnn_tokenizer.json'\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open(tokenizer_path, 'w') as f:\n",
    "    f.write(tokenizer_json)\n",
    "print(f\"Tokenizer guardado en: {tokenizer_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicción con Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_sentiment(text, model, tokenizer, max_len=MAX_LEN):\n",
    "    \"\"\"\n",
    "    Predice el sentimiento de un texto usando el modelo entrenado\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto para predecir\n",
    "        model: Modelo entrenado\n",
    "        tokenizer: Tokenizer ajustado a los datos de entrenamiento\n",
    "        max_len (int): Longitud máxima de secuencia\n",
    "        \n",
    "    Returns:\n",
    "        dict: Predicción con detalles\n",
    "    \"\"\"\n",
    "    # Limpiar el texto\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Convertir a secuencia\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    \n",
    "    # Padding\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    \n",
    "    # Predecir\n",
    "    prediction = model.predict(padded_sequence)[0][0]\n",
    "    \n",
    "    # Determinar sentimiento\n",
    "    sentiment = \"positivo\" if prediction >= 0.5 else \"negativo\"\n",
    "    confidence = prediction if prediction >= 0.5 else 1 - prediction\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'cleaned_text': cleaned_text,\n",
    "        'sentiment': sentiment,\n",
    "        'confidence': float(confidence),\n",
    "        'raw_score': float(prediction)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejemplos de tweets para probar\n",
    "example_tweets = [\n",
    "    \"I absolutely love this new phone! It's amazing and works perfectly.\",\n",
    "    \"This movie was terrible. Complete waste of time and money.\",\n",
    "    \"The weather today is okay, nothing special.\",\n",
    "    \"Can't believe how bad the customer service was. Never going back!\",\n",
    "    \"Just had the best meal of my life at that new restaurant downtown!\"\n",
    "]\n",
    "\n",
    "# Realizar predicciones\n",
    "results = []\n",
    "for tweet in example_tweets:\n",
    "    result = predict_sentiment(tweet, model, tokenizer)\n",
    "    results.append(result)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nEjemplo {i+1}:\")\n",
    "    print(f\"Texto: {result['text']}\")\n",
    "    print(f\"Sentimiento: {result['sentiment']}\")\n",
    "    print(f\"Confianza: {result['confidence']:.4f}\")\n",
    "    print(f\"Puntuación: {result['raw_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusiones sobre el Modelo RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook, hemos implementado y entrenado una Red Neuronal Recurrente (RNN) básica para la clasificación de sentimientos en tweets. Algunas observaciones importantes:\n",
    "\n",
    "1. **Arquitectura**: La RNN básica consta de una capa de embedding seguida de una capa SimpleRNN y una capa densa para la clasificación binaria.\n",
    "\n",
    "2. **Métricas de rendimiento**: El modelo alcanzó un accuracy de X.XX en el conjunto de prueba, con una precisión de X.XX y un recall de X.XX. (Estos valores se completarán después del entrenamiento)\n",
    "\n",
    "3. **Manejo del desbalanceo**: Utilizamos la estrategia de oversampling para equilibrar las clases, lo que mejoró significativamente el rendimiento en la clase minoritaria (tweets positivos).\n",
    "\n",
    "4. **Limitaciones**:\n",
    "   - Las RNN básicas pueden tener dificultades para capturar dependencias a largo plazo en el texto.\n",
    "   - El modelo podría beneficiarse de un preprocesamiento más avanzado o de características adicionales.\n",
    "\n",
    "5. **Próximos pasos**: Implementaremos modelos más avanzados como LSTM y BiLSTM con atención para comparar su rendimiento con esta línea base RNN.\n",
    "\n",
    "La RNN básica proporciona un punto de referencia útil, pero esperamos que arquitecturas más sofisticadas puedan mejorar el rendimiento en esta tarea de análisis de sentimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
