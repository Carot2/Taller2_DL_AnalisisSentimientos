# An√°lisis de Sentimiento en Tweets con RNN, LSTM y BiLSTM + Atenci√≥n

Este proyecto implementa y compara diferentes arquitecturas de redes neuronales recurrentes para la clasificaci√≥n de sentimientos en tweets.


## √çndice
1. [Arquitecturas utilizadas](#arquitecturas-utilizadas)
   - [¬øQu√© es una RNN?](#qu√©-es-una-rnn)
   - [¬øQu√© es una LSTM?](#qu√©-es-una-lstm)
   - [¬øQu√© es una BiLSTM con atenci√≥n?](#qu√©-es-una-bilstm-con-atenci√≥n)
2. [Introducci√≥n a la problem√°tica](#introducci√≥n-a-la-problem√°tica)
3. [Exploraci√≥n del dataset](#exploraci√≥n-del-dataset)
   - [Descripci√≥n de las variables](#descripci√≥n-de-las-variables)
   - [An√°lisis de caracter√≠sticas y preprocesamiento](#an√°lisis-de-las-caracter√≠sticas-y-preprocesamiento-de-datos)
4. [Implementaci√≥n de la red neuronal](#implementaci√≥n-de-la-red-neuronal)
5. [Estructuraci√≥n del repositorio](#estructuraci√≥n-del-repositorio)
6. [Instrucciones de uso](#instrucciones-de-uso-de-la-red-neuronal-y-rendimiento-obtenido)
   - [Requisitos previos](#requisitos-previos)
   - [Instalaci√≥n](#instalaci√≥n)
   - [C√≥mo entrenar el modelo](#c√≥mo-entrenar-el-modelo-desde-trainpy)
   - [C√≥mo evaluar el modelo](#c√≥mo-evaluar-el-modelo-usando-evaluatepy)
   - [C√≥mo hacer predicciones](#c√≥mo-hacer-predicciones-con-predictpy)
7. [Rendimiento obtenido](#rendimiento-obtenido)
8. [Conclusiones](#conclusiones)


## ‚ö°Ô∏è Arquitecturas utilizadas

En este proyecto se implementaron y compararon tres tipos de arquitecturas de redes neuronales recurrentes para el an√°lisis de sentimientos en Tweets:

### ¬øQu√© es una RNN?

![Red Neuronal Recurrente](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/RNN.png)

Una Red Neuronal Recurrente (RNN) es un tipo de red dise√±ada para procesar secuencias de datos. A diferencia de una red neuronal tradicional, una RNN tiene una "memoria interna" que le permite recordar informaci√≥n de entradas anteriores, lo cual es √∫til en tareas como procesamiento de lenguaje natural. Sin embargo, las RNN simples suelen sufrir del problema de desvanecimiento del gradiente, lo que limita su capacidad para aprender dependencias a largo plazo.

### ¬øQu√© es una LSTM?

![Red Neuronal LSTM](https://mlarchive.com/wp-content/uploads/2024/04/New-Project-3-1-1024x607-1024x585.png)
La Long Short-Term Memory (LSTM) es una variante de la RNN dise√±ada para resolver los problemas de memoria de largo plazo. Utiliza compuertas (gate mechanisms) que controlan el flujo de informaci√≥n, permitiendo al modelo "recordar" o "olvidar" informaci√≥n seg√∫n sea necesario. Esto la hace mucho m√°s efectiva para tareas como clasificaci√≥n de sentimientos en texto.


### ¬øQu√© es una BiLSTM con atenci√≥n?

![BILSTM + ATTENTION](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/BILSTM_ATTENTION.png)

Una BiLSTM (Bidirectional LSTM) procesa la secuencia tanto hacia adelante como hacia atr√°s, capturando contexto tanto previo como posterior en una oraci√≥n. Esto mejora significativamente la comprensi√≥n sem√°ntica. Adem√°s, al a√±adir un mecanismo de **atenci√≥n**, el modelo puede aprender a enfocarse en las palabras m√°s relevantes del texto para tomar decisiones de clasificaci√≥n, mejorando la interpretaci√≥n y el rendimiento en tareas complejas como el an√°lisis de sentimiento.

## ‚ö°Ô∏è Introducci√≥n a la problem√°tica

### Aplicaciones del an√°lisis de sentimiento en redes sociales

El **an√°lisis de sentimiento** es una t√©cnica clave del procesamiento de lenguaje natural (NLP) que busca identificar y extraer opiniones, emociones o actitudes expresadas en texto. En el contexto de redes sociales como Twitter, esta t√©cnica tiene aplicaciones muy valiosas:

- **Monitoreo de la opini√≥n p√∫blica**: detectar c√≥mo reaccionan los usuarios ante eventos, marcas o personalidades.
- **Gesti√≥n de reputaci√≥n**: las empresas pueden actuar r√°pidamente ante comentarios negativos o detectar embajadores de marca.
- **Marketing dirigido**: segmentaci√≥n de usuarios seg√∫n sus actitudes o emociones.
- **Sistemas de recomendaci√≥n**: ofrecer contenido, productos o servicios personalizados en funci√≥n del sentimiento expresado.
- **An√°lisis pol√≠tico o social**: comprender el sentimiento colectivo ante decisiones pol√≠ticas o eventos sociales.

### Importancia de modelar secuencias y contexto ling√º√≠stico

A diferencia de tareas de clasificaci√≥n m√°s simples, en el an√°lisis de sentimiento **el orden de las palabras y su contexto importan enormemente**. Por ejemplo:

> *"I don't like this"* no es lo mismo que *"I like this"*

Modelos como las RNN, LSTM y BiLSTM son esenciales porque:
- Permiten modelar **dependencias temporales** entre palabras.
- Capturan **el contexto ling√º√≠stico**, incluyendo negaciones, iron√≠as o emociones impl√≠citas.
- En el caso de BiLSTM, permiten analizar un texto **en ambas direcciones** (inicio ‚Üí fin y fin ‚Üí inicio).
- El mecanismo de **atenci√≥n** mejora la capacidad del modelo para "enfocarse" en las palabras m√°s relevantes dentro del tweet.

---

## ‚ö°Ô∏è Exploraci√≥n del dataset

Para entrenar nuestros modelos, trabajamos con un conjunto de datos de tweets p√∫blicos extra√≠do de [este repositorio de GitHub](https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv). El dataset contiene **31,962 tweets en ingl√©s**, cada uno etiquetado con su **sentimiento binario**: positivo o negativo.

### **Descripci√≥n de las variables**

| Columna | Descripci√≥n |
|---------|-------------|
| `id`    | Identificador √∫nico del tweet. |
| `label` | Sentimiento asociado al tweet (`0`: negativo, `1`: positivo). |
| `tweet` | Texto completo del tweet, que puede contener menciones, hashtags, emojis, URLs y s√≠mbolos. |

se verific√≥ que el dataset **no contiene valores nulos ni duplicados**, lo que facilita el proceso de preprocesamiento y entrenamiento de modelos sin requerir limpieza adicional por valores faltantes.

--

## üìä An√°lisis de caracter√≠sticas y preprocesamiento de datos

A partir del an√°lisis exploratorio del conjunto de datos, se pueden destacar las siguientes observaciones clave:

### 1. üßÆ Desbalanceo de clases

El dataset presenta un **fuerte desbalanceo de clases**, con:

- `29,720` tweets etiquetados como **negativos**
- `2,242` tweets etiquetados como **positivos**

Esto representa una proporci√≥n de aproximadamente **13:1 a favor de la clase negativa**, como puede observarse en la siguiente gr√°fica:
![Distribuci√≥n de Tweets](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/DistribucionTweets.png)


### 2. üî† Longitud de los tweets y tokens

- El an√°lisis inicial muestra que:
  - El **95%** de los tweets negativos tiene una longitud menor o igual a **116 caracteres**
  - El **95%** de los tweets positivos no supera los **113 caracteres**

Esto justifica la elecci√≥n de una **longitud m√°xima de 120 caracteres** como l√≠mite razonable para los modelos.

Posteriormente, al **tokenizar** los textos, se observ√≥ que el **95% de los tweets contiene como m√°ximo 33 tokens**. Esta informaci√≥n se us√≥ para definir el par√°metro `max_len = 33` durante el padding, lo que permite una representaci√≥n **uniforme, eficiente y sin p√©rdida de informaci√≥n**.
![Distribuci√≥n de Tokens](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/LongTokens.png)


### 3. üßæ Palabras m√°s frecuentes por clase

Se realiz√≥ un an√°lisis de las palabras m√°s frecuentes en tweets negativos y positivos. Los resultados muestran diferencias claras en el vocabulario utilizado, lo que indica que los modelos podr√≠an aprender patrones relevantes para clasificar los tweets correctamente.

- En los tweets negativos predominan t√©rminos emocionales o expresivos como `love`, `happy`, `day`, `life`.

![PalabrasNegativas](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/NubePalabrasNegativo.png)

- En los positivos (seg√∫n etiqueta) se observan palabras relacionadas a pol√≠tica o ideolog√≠as como `trump`, `racist`, `libtard`.
![PalabrasPositivas](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/NubePalabrasPositivo.png)

Esto puede deberse a sesgos en el dataset original, lo cual tambi√©n debe tenerse en cuenta.

---

### 4. üß™ Preprocesamiento aplicado

Para preparar los textos para el modelo, se aplicaron las siguientes transformaciones:

- Conversi√≥n a **min√∫sculas**
- Eliminaci√≥n de **menciones** (`@user`)
- Eliminaci√≥n de **hashtags**, manteniendo la palabra clave
- Remoci√≥n de **URLs**
- Eliminaci√≥n de **emojis, caracteres especiales y puntuaci√≥n**
- Reducci√≥n de **espacios m√∫ltiples**
- Tokenizaci√≥n y padding uniforme (`max_len = 33`)

---


### 5. ‚öñÔ∏è Estrategias para abordar el desbalanceo ---

Debido al fuerte desbalance, se consideraron las siguientes estrategias:

- **Oversampling**: duplicar ejemplos de la clase minoritaria para equilibrar las proporciones.
- **SMOTE**: t√©cnica de sobre-muestreo sint√©tico que genera ejemplos nuevos de la clase minoritaria.
- **Class Weights**: ponderar la p√©rdida durante el entrenamiento para penalizar m√°s los errores en la clase minoritaria.

En este proyecto, se experiment√≥ principalmente con **oversampling** y `class_weight`, dependiendo del modelo implementado.







## Estructura del Repositorio

```
mi_proyecto_sentimiento/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploracion.ipynb         # Exploraci√≥n y preprocesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ 02_entrenamiento_RNN.ipynb   # Entrenamiento y evaluaci√≥n del modelo RNN
‚îÇ   ‚îú‚îÄ‚îÄ 03_entrenamiento_LSTM.ipynb  # Entrenamiento y evaluaci√≥n del modelo LSTM
‚îÇ   ‚îî‚îÄ‚îÄ 04_BiLSTM_atencion.ipynb     # Entrenamiento y evaluaci√≥n del modelo BiLSTM+Atenci√≥n
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py               # Funciones para cargar y preprocesar los datos
‚îÇ   ‚îú‚îÄ‚îÄ model_rnn.py                 # Implementaci√≥n del modelo RNN
‚îÇ   ‚îú‚îÄ‚îÄ model_lstm.py                # Implementaci√≥n del modelo LSTM
‚îÇ   ‚îú‚îÄ‚îÄ model_bilstm_attention.py    # Implementaci√≥n del modelo BiLSTM+Atenci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ train.py                     # Funciones de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                  # Funciones de evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                     # Funciones auxiliares
‚îú‚îÄ‚îÄ models/                          # Directorio para guardar modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ rnn_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_attention_model.h5
‚îÇ   ‚îî‚îÄ‚îÄ README.md                    # Descripci√≥n de los modelos guardados
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias del proyecto
‚îî‚îÄ‚îÄ .gitignore                       # Archivos a ignorar en Git
```

## Requisitos y Dependencias

Para ejecutar este proyecto, necesitas tener instalado Python 3.8 o superior y las siguientes bibliotecas:

```
pip install -r requirements.txt
```

## Uso

### Carga y Exploraci√≥n de Datos

El dataset se carga directamente desde una URL p√∫blica:

```python
import pandas as pd
import tensorflow as tf

url = "https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv"
csv_path = tf.keras.utils.get_file("twitter_sentiment.csv", url)
df = pd.read_csv(csv_path)
```

### üöÄ Entrenamiento de Modelos

Para entrenar los modelos (RNN, LSTM o BiLSTM+Atenci√≥n) tienes **dos opciones** seg√∫n tu preferencia:

#### Opci√≥n 1: Usando Jupyter Notebooks (modo interactivo)

1. Abre una terminal (CMD, PowerShell o terminal de VSCode).
2. Ub√≠cate en la carpeta ra√≠z del proyecto:

   ```bash
   cd "C:\Users\USER\Documentos\Maestr√≠a\Deep Learning\Taller2_DL_AnalisisSentimientos"

Lanza el servidor de Jupyter Notebook:
```bash
   jupyter notebook
```
Se abrir√° una ventana en tu navegador web. Dentro del navegador:
   Abre la carpeta notebooks/.

3. Ejecuta uno por uno los siguientes notebooks para entrenar cada modelo:

   02_entrenamiento_RNN.ipynb (para RNN)
   03_entrenamiento_LSTM.ipynb (para LSTM)
   04_BiLSTM_atencion.ipynb (para BiLSTM+Atenci√≥n)

Corre las celdas dentro de cada notebook manualmente (Shift + Enter).

‚úÖ Ideal si quieres ver gr√°ficas de entrenamiento y outputs en tiempo real.

#### Opci√≥n 2: Usando scripts desde Terminal (modo directo)
Si prefieres entrenar los modelos directamente desde la terminal, sin abrir Jupyter, puedes ejecutar:

```bash
--RNN python -m src.train --model rnn --epochs 5 --batch_size 128
--LSTM python -m src.train --model lstm --epochs 5 --batch_size 128
--BiLSTM+Atenci√≥n python -m src.train --model bilstm_attention --epochs 5 --batch_size 128
```

üìå Notas importantes:

* Los modelos entrenados se guardar√°n autom√°ticamente en la carpeta /models/.
* El tokenizer utilizado tambi√©n se guardar√° como archivo .json.
* Puedes personalizar el n√∫mero de √©pocas (--epochs), tama√±o de batch (--batch_size), balanceo (--balance) y si quieres usar pesos de clase (--class_weights).

## ‚öôÔ∏è Estrategias de Balanceo de Clases

Por defecto, **los modelos se entrenan sin aplicar t√©cnicas de balanceo de clases**.  
Esto significa que el dataset original, que presenta un fuerte desbalance (93% positivos vs 7% negativos), se utiliza tal cual para entrenar RNN, LSTM y BiLSTM+Atenci√≥n.


## üöÄ C√≥mo entrenar modelos aplicando t√©cnicas de balanceo

### 1. Entrenar con Oversampling

```bash
python -m src.train --model bilstm_attention --balance oversampling --epochs 5 --batch_size 128
python -m src.train --model lstm --balance oversampling --epochs 5 --batch_size 128
python -m src.train --model rnn --balance oversampling --epochs 5 --batch_size 128
```
### 2. Entrenar con SMOTE

```bash
python -m src.train --model bilstm_attention --balance smote --epochs 5 --batch_size 128
python -m src.train --model lstm --balance smote --epochs 5 --batch_size 128
python -m src.train --model rnn --balance smote --epochs 5 --batch_size 128
```
### 2. Entrenar con Class Weights

```bash
python -m src.train --model bilstm_attention --balance class_weights --epochs 5 --batch_size 128
python -m src.train --model lstm --balance class_weights --epochs 5 --batch_size 128
python -m src.train --model rnn --balance class_weights --epochs 5 --batch_size 128
```
## üìà Evaluaci√≥n y Predicci√≥n de Modelos

Una vez entrenados los modelos, puedes evaluarlos, comparar su rendimiento o hacer predicciones individuales de sentimientos usando el script `src/evaluate.py`.

Aseg√∫rate de estar ubicado en la carpeta ra√≠z del proyecto antes de ejecutar los siguientes comandos.

> **Nota:**  
> Los comandos de evaluaci√≥n funcionan con cualquier modelo `.h5` entrenado, ya sea sobre datos balanceados (oversampling, SMOTE, class weights) o no balanceados.  
> Aseg√∫rate de seleccionar el modelo correspondiente seg√∫n la t√©cnica que hayas utilizado en el entrenamiento.


---

### üîé Evaluar un solo modelo

Eval√∫a un modelo entrenado (`.h5`) sobre un conjunto de datos de prueba:

```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --test_size 0.2
python -m src.evaluate --model models/lstm_model.h5 --test_size 0.2
python -m src.evaluate --model models/rnn_model.h5 --test_size 0.2
```

### ü•Ω Evaluar un modelo usando un tokenizer espec√≠fico
Si deseas usar un tokenizer .json diferente al que se infiere por defecto:
```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --tokenizer models/bilstm_attention_tokenizer.json
```

### üî¨ Predecir el sentimiento de un texto personalizado
Puedes usar un modelo entrenado para predecir el sentimiento de un nuevo texto:
```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --tokenizer models/bilstm_attention_tokenizer.json --text "I love this product!"
```

### üìä Comparar varios modelos
Compara autom√°ticamente todos los modelos .h5 en la carpeta /models/, evaluando su precisi√≥n, recall, F1-score, etc.:
```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --compare
```
Nota: --model debe apuntar a un modelo ubicado dentro de la carpeta que contiene los dem√°s modelos para comparar.

## üìà Resultados

A continuaci√≥n se presentan las m√©tricas de rendimiento de cada modelo evaluado:
### Modelos con Oversampling
| Modelo          | Accuracy | Precision | Recall    | F1-Score |
|:----------------|:--------:|:---------:|:---------:|:--------:|
| BiLSTM+Atenci√≥n | 0.497575 | 0.0799    | 0.5870    | 0.1407   |
| LSTM            | 0.600501 | 0.0877    | 0.5000    | 0.1492   |
| RNN             | 0.750821 | 0.0836    | 0.2566    | 0.1261   |

### Modelos con SMOTE

| Modelo          | Accuracy | Precision | Recall    | F1-Score |
|:----------------|:--------:|:---------:|:---------:|:--------:|
| BiLSTM+Atenci√≥n | 0.663695 | 0.0872    | 0.4017    | 0.1434   |
| LSTM            | 0.689973 | 0.0785    | 0.3191    | 0.1261   |
| RNN             | 0.637885 | 0.0762    | 0.3750    | 0.1267   |

### Modelos con Class_weights

| Modelo          | Accuracy | Precision | Recall    | F1-Score |
|:----------------|:--------:|:---------:|:---------:|:--------:|
| BiLSTM+Atenci√≥n | 0.926326 | 0.129032  | 0.00892   | 0.016701 |
| LSTM            | 0.929767 | 0.0000    | 0.00000   | 0.0000   |
| RNN             | 0.929923 | 0.0000    | 0.00000   | 0.0000   |

---

### üìä An√°lisis Comparativo de Modelos

- El modelo **RNN** alcanz√≥ el mayor **accuracy** (92.99%), sin embargo, **fall√≥ en detectar ejemplos positivos**, mostrando una precisi√≥n y recall de 0.0%.
- El modelo **LSTM** mejor√≥ ligeramente la **precision** respecto a RNN, pero el **recall** sigue siendo muy bajo, indicando dificultades para identificar la clase minoritaria.
- El modelo **BiLSTM+Atenci√≥n**, aunque present√≥ un leve descenso en **accuracy** (92.01%), logr√≥ un **mejor equilibrio** entre precisi√≥n y recall en comparaci√≥n a los anteriores, gracias al mecanismo de atenci√≥n.

> **Conclusi√≥n preliminar:** El modelo BiLSTM+Atenci√≥n ofrece un mejor compromiso entre sensibilidad (recall) y precisi√≥n para un dataset desbalanceado.

---

## ‚öñÔ∏è Manejo del Desbalanceo de Clases

Para abordar el severo desbalance en el dataset original (29,720 negativos vs 2,242 positivos), se aplicaron las siguientes estrategias:

1. **Oversampling**: Duplicaci√≥n aleatoria de ejemplos de la clase minoritaria para igualar el n√∫mero de ejemplos de la clase mayoritaria.
2. **SMOTE (Synthetic Minority Over-sampling Technique)**: Generaci√≥n sint√©tica de nuevos ejemplos de la clase minoritaria en el espacio de caracter√≠sticas.

Ambas estrategias fueron evaluadas en diferentes etapas del proyecto.  
Los resultados sugieren que **combinar t√©cnicas de balanceo con arquitecturas avanzadas** (como BiLSTM con atenci√≥n) mejora la capacidad del modelo para detectar correctamente la clase minoritaria.

---

## ‚ö°Ô∏è Rendimiento obtenido

Tras entrenar y evaluar las tres arquitecturas propuestas (RNN, LSTM y BiLSTM+Atenci√≥n) en el an√°lisis de sentimiento de tweets, se observaron los siguientes resultados:

- **RNN**: Alcanz√≥ el mayor accuracy general (~92.99%), pero con incapacidad para identificar correctamente la clase minoritaria (recall = 0.00%).
- **LSTM**: Mejor√≥ marginalmente la capacidad de predicci√≥n de ejemplos positivos en comparaci√≥n con la RNN, pero el recall a√∫n result√≥ muy bajo (~0.0045).
- **BiLSTM+Atenci√≥n**: Logr√≥ un mejor balance entre precisi√≥n y sensibilidad, incrementando el recall (~2.90%) y el F1-Score (~4.84%), sacrificando ligeramente el accuracy.

> **Conclusi√≥n de rendimiento**: Aunque la RNN obtuvo un mayor accuracy global, el modelo BiLSTM+Atenci√≥n demostr√≥ ser superior en la detecci√≥n de la clase minoritaria, lo cual es crucial en datasets altamente desbalanceados como el evaluado.

## üß† Conclusiones

- El an√°lisis de sentimiento en datasets desbalanceados requiere algo m√°s que optimizar el accuracy general; es fundamental mejorar m√©tricas como el **recall** y el **F1-score**.
- Modelos b√°sicos como la **RNN** tienden a sesgarse hacia la clase mayoritaria, ignorando ejemplos de clases minoritarias.
- **LSTM** mejora levemente la capacidad de generalizaci√≥n, pero no es suficiente por s√≠ sola en presencia de desbalance severo.
- **BiLSTM combinada con mecanismos de Atenci√≥n** demostr√≥ ser la arquitectura m√°s efectiva, logrando capturar contexto bidireccional y priorizar palabras clave relevantes en los tweets.
- La implementaci√≥n de t√©cnicas de balanceo como **oversampling** y **class_weight** son imprescindibles para mejorar la detecci√≥n de ejemplos de la clase minoritaria.
- Para proyectos futuros, se recomienda explorar t√©cnicas adicionales como **focal loss** y **estrategias de data augmentation textual** para seguir mejorando la sensibilidad del modelo ante ejemplos minoritarios.

> **En conclusi√≥n:** BiLSTM+Atenci√≥n, junto con estrategias de balanceo, proporciona una soluci√≥n m√°s robusta y adecuada para el an√°lisis de sentimientos en entornos de datos desbalanceados.


## Autores del Proyecto ü§ì

Este proyecto fue desarrollado por:

* [Jerem√≠as Pab√≥n](https://github.com/jeremiaspabon) 
* [Gers√≥n Juli√°n Rinc√≥n](https://github.com/Julk-ui) 
* [Andr√©s Bravo](https://github.com/pipebravo10) 
* [Carolina Tobaria](https://github.com/Carot2) 