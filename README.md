# An√°lisis de Sentimiento en Tweets con RNN, LSTM y BiLSTM + Atenci√≥n

Este proyecto implementa y compara diferentes arquitecturas de redes neuronales recurrentes para la clasificaci√≥n de sentimientos en tweets.


## √çndice
1. [Arquitecturas utilizadas](#arquitecturas-utilizadas)
   - [¬øQu√© es una RNN?](#qu√©-es-una-rnn)
   - [¬øQu√© es una LSTM?](#qu√©-es-una-lstm)
   - [¬øQu√© es una BiLSTM con atenci√≥n?](#qu√©-es-una-bilstm-con-atenci√≥n)
2. [Introducci√≥n a la problem√°tica](#introducci√≥n-a-la-problem√°tica)
3. [Exploraci√≥n del dataset](#exploraci√≥n-del-dataset)
   - [Descripci√≥n de las variables](#descripci√≥n-de-las-variables)
   - [An√°lisis de caracter√≠sticas y preprocesamiento](#an√°lisis-de-las-caracter√≠sticas-y-preprocesamiento-de-datos)
4. [Implementaci√≥n de la red neuronal](#implementaci√≥n-de-la-red-neuronal)
5. [Estructuraci√≥n del repositorio](#estructuraci√≥n-del-repositorio)
6. [Instrucciones de uso](#instrucciones-de-uso-de-la-red-neuronal-y-rendimiento-obtenido)
   - [Requisitos previos](#requisitos-previos)
   - [Instalaci√≥n](#instalaci√≥n)
   - [C√≥mo entrenar el modelo](#c√≥mo-entrenar-el-modelo-desde-trainpy)
   - [C√≥mo evaluar el modelo](#c√≥mo-evaluar-el-modelo-usando-evaluatepy)
   - [C√≥mo hacer predicciones](#c√≥mo-hacer-predicciones-con-predictpy)
7. [Rendimiento obtenido](#rendimiento-obtenido)
8. [Conclusiones](#conclusiones)


## ‚ö°Ô∏è Arquitecturas utilizadas

En este proyecto se implementaron y compararon tres tipos de arquitecturas de redes neuronales recurrentes para el an√°lisis de sentimientos en Tweets:

### ¬øQu√© es una RNN?

![Red Neuronal Recurrente](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/RNN.png)

Una Red Neuronal Recurrente (RNN) es un tipo de red dise√±ada para procesar secuencias de datos. A diferencia de una red neuronal tradicional, una RNN tiene una "memoria interna" que le permite recordar informaci√≥n de entradas anteriores, lo cual es √∫til en tareas como procesamiento de lenguaje natural. Sin embargo, las RNN simples suelen sufrir del problema de desvanecimiento del gradiente, lo que limita su capacidad para aprender dependencias a largo plazo.

### ¬øQu√© es una LSTM?

![Red Neuronal LSTM](https://mlarchive.com/wp-content/uploads/2024/04/New-Project-3-1-1024x607-1024x585.png)
La Long Short-Term Memory (LSTM) es una variante de la RNN dise√±ada para resolver los problemas de memoria de largo plazo. Utiliza compuertas (gate mechanisms) que controlan el flujo de informaci√≥n, permitiendo al modelo "recordar" o "olvidar" informaci√≥n seg√∫n sea necesario. Esto la hace mucho m√°s efectiva para tareas como clasificaci√≥n de sentimientos en texto.


### ¬øQu√© es una BiLSTM con atenci√≥n?

![BILSTM + ATTENTION](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/BILSTM_ATTENTION.png)

Una BiLSTM (Bidirectional LSTM) procesa la secuencia tanto hacia adelante como hacia atr√°s, capturando contexto tanto previo como posterior en una oraci√≥n. Esto mejora significativamente la comprensi√≥n sem√°ntica. Adem√°s, al a√±adir un mecanismo de **atenci√≥n**, el modelo puede aprender a enfocarse en las palabras m√°s relevantes del texto para tomar decisiones de clasificaci√≥n, mejorando la interpretaci√≥n y el rendimiento en tareas complejas como el an√°lisis de sentimiento.

## ‚ö°Ô∏è Introducci√≥n a la problem√°tica

### Aplicaciones del an√°lisis de sentimiento en redes sociales

El **an√°lisis de sentimiento** es una t√©cnica clave del procesamiento de lenguaje natural (NLP) que busca identificar y extraer opiniones, emociones o actitudes expresadas en texto. En el contexto de redes sociales como Twitter, esta t√©cnica tiene aplicaciones muy valiosas:

- **Monitoreo de la opini√≥n p√∫blica**: detectar c√≥mo reaccionan los usuarios ante eventos, marcas o personalidades.
- **Gesti√≥n de reputaci√≥n**: las empresas pueden actuar r√°pidamente ante comentarios negativos o detectar embajadores de marca.
- **Marketing dirigido**: segmentaci√≥n de usuarios seg√∫n sus actitudes o emociones.
- **Sistemas de recomendaci√≥n**: ofrecer contenido, productos o servicios personalizados en funci√≥n del sentimiento expresado.
- **An√°lisis pol√≠tico o social**: comprender el sentimiento colectivo ante decisiones pol√≠ticas o eventos sociales.

### Importancia de modelar secuencias y contexto ling√º√≠stico

A diferencia de tareas de clasificaci√≥n m√°s simples, en el an√°lisis de sentimiento **el orden de las palabras y su contexto importan enormemente**. Por ejemplo:

> *"I don't like this"* no es lo mismo que *"I like this"*

Modelos como las RNN, LSTM y BiLSTM son esenciales porque:
- Permiten modelar **dependencias temporales** entre palabras.
- Capturan **el contexto ling√º√≠stico**, incluyendo negaciones, iron√≠as o emociones impl√≠citas.
- En el caso de BiLSTM, permiten analizar un texto **en ambas direcciones** (inicio ‚Üí fin y fin ‚Üí inicio).
- El mecanismo de **atenci√≥n** mejora la capacidad del modelo para "enfocarse" en las palabras m√°s relevantes dentro del tweet.

---

## ‚ö°Ô∏è Exploraci√≥n del dataset

Para entrenar nuestros modelos, trabajamos con un conjunto de datos de tweets p√∫blicos extra√≠do de [este repositorio de GitHub](https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv). El dataset contiene **31,962 tweets en ingl√©s**, cada uno etiquetado con su **sentimiento binario**: positivo o negativo.

### **Descripci√≥n de las variables**

| Columna | Descripci√≥n |
|---------|-------------|
| `id`    | Identificador √∫nico del tweet. |
| `label` | Sentimiento asociado al tweet (`0`: negativo, `1`: positivo). |
| `tweet` | Texto completo del tweet, que puede contener menciones, hashtags, emojis, URLs y s√≠mbolos. |

se verific√≥ que el dataset **no contiene valores nulos ni duplicados**, lo que facilita el proceso de preprocesamiento y entrenamiento de modelos sin requerir limpieza adicional por valores faltantes.

--

## üìä An√°lisis de caracter√≠sticas y preprocesamiento de datos

A partir del an√°lisis exploratorio del conjunto de datos, se pueden destacar las siguientes observaciones clave:

### 1. üßÆ Desbalanceo de clases

El dataset presenta un **fuerte desbalanceo de clases**, con:

- `29,720` tweets etiquetados como **negativos**
- `2,242` tweets etiquetados como **positivos**

Esto representa una proporci√≥n de aproximadamente **13:1 a favor de la clase negativa**, como puede observarse en la siguiente gr√°fica:
![Distribuci√≥n de Tweets](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/DistribucionTweets.png)


### 2. üî† Longitud de los tweets y tokens

- El an√°lisis inicial muestra que:
  - El **95%** de los tweets negativos tiene una longitud menor o igual a **116 caracteres**
  - El **95%** de los tweets positivos no supera los **113 caracteres**

Esto justifica la elecci√≥n de una **longitud m√°xima de 120 caracteres** como l√≠mite razonable para los modelos.

Posteriormente, al **tokenizar** los textos, se observ√≥ que el **95% de los tweets contiene como m√°ximo 33 tokens**. Esta informaci√≥n se us√≥ para definir el par√°metro `max_len = 33` durante el padding, lo que permite una representaci√≥n **uniforme, eficiente y sin p√©rdida de informaci√≥n**.
![Distribuci√≥n de Tokens](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/LongTokens.png)


### 3. üßæ Palabras m√°s frecuentes por clase

Se realiz√≥ un an√°lisis de las palabras m√°s frecuentes en tweets negativos y positivos. Los resultados muestran diferencias claras en el vocabulario utilizado, lo que indica que los modelos podr√≠an aprender patrones relevantes para clasificar los tweets correctamente.

- En los tweets negativos predominan t√©rminos emocionales o expresivos como `love`, `happy`, `day`, `life`.

![PalabrasNegativas](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/NubePalabrasNegativo.png)

- En los positivos (seg√∫n etiqueta) se observan palabras relacionadas a pol√≠tica o ideolog√≠as como `trump`, `racist`, `libtard`.
![PalabrasPositivas](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/NubePalabrasPositivo.png)

Esto puede deberse a sesgos en el dataset original, lo cual tambi√©n debe tenerse en cuenta.

---

### 4. üß™ Preprocesamiento aplicado

Para preparar los textos para el modelo, se aplicaron las siguientes transformaciones:

- Conversi√≥n a **min√∫sculas**
- Eliminaci√≥n de **menciones** (`@user`)
- Eliminaci√≥n de **hashtags**, manteniendo la palabra clave
- Remoci√≥n de **URLs**
- Eliminaci√≥n de **emojis, caracteres especiales y puntuaci√≥n**
- Reducci√≥n de **espacios m√∫ltiples**
- Tokenizaci√≥n y padding uniforme (`max_len = 33`)

---


### 5. ‚öñÔ∏è Estrategias para abordar el desbalanceo ---

Debido al fuerte desbalance, se consideraron las siguientes estrategias:

- **Oversampling**: duplicar ejemplos de la clase minoritaria para equilibrar las proporciones.
- **SMOTE**: t√©cnica de sobre-muestreo sint√©tico que genera ejemplos nuevos de la clase minoritaria.
- **Class Weights**: ponderar la p√©rdida durante el entrenamiento para penalizar m√°s los errores en la clase minoritaria.

En este proyecto, se experiment√≥ principalmente con **oversampling** y `class_weight`, dependiendo del modelo implementado.







## Estructura del Repositorio

```
mi_proyecto_sentimiento/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploracion.ipynb         # Exploraci√≥n y preprocesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ 02_entrenamiento_RNN.ipynb   # Entrenamiento y evaluaci√≥n del modelo RNN
‚îÇ   ‚îú‚îÄ‚îÄ 03_entrenamiento_LSTM.ipynb  # Entrenamiento y evaluaci√≥n del modelo LSTM
‚îÇ   ‚îî‚îÄ‚îÄ 04_BiLSTM_atencion.ipynb     # Entrenamiento y evaluaci√≥n del modelo BiLSTM+Atenci√≥n
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py               # Funciones para cargar y preprocesar los datos
‚îÇ   ‚îú‚îÄ‚îÄ model_rnn.py                 # Implementaci√≥n del modelo RNN
‚îÇ   ‚îú‚îÄ‚îÄ model_lstm.py                # Implementaci√≥n del modelo LSTM
‚îÇ   ‚îú‚îÄ‚îÄ model_bilstm_attention.py    # Implementaci√≥n del modelo BiLSTM+Atenci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ train.py                     # Funciones de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                  # Funciones de evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                     # Funciones auxiliares
‚îú‚îÄ‚îÄ models/                          # Directorio para guardar modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ rnn_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_attention_model.h5
‚îÇ   ‚îî‚îÄ‚îÄ README.md                    # Descripci√≥n de los modelos guardados
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias del proyecto
‚îî‚îÄ‚îÄ .gitignore                       # Archivos a ignorar en Git
```

## Requisitos y Dependencias

Para ejecutar este proyecto, necesitas tener instalado Python 3.8 o superior y las siguientes bibliotecas:

```
pip install -r requirements.txt
```

## Uso

### Carga y Exploraci√≥n de Datos

El dataset se carga directamente desde una URL p√∫blica:

```python
import pandas as pd
import tensorflow as tf

url = "https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv"
csv_path = tf.keras.utils.get_file("twitter_sentiment.csv", url)
df = pd.read_csv(csv_path)
```

### üöÄ Entrenamiento de Modelos

Para entrenar los modelos (RNN, LSTM o BiLSTM+Atenci√≥n) tienes **dos opciones** seg√∫n tu preferencia:

#### Opci√≥n 1: Usando Jupyter Notebooks (modo interactivo)

1. Abre una terminal (CMD, PowerShell o terminal de VSCode).
2. Ub√≠cate en la carpeta ra√≠z del proyecto:

   ```bash
   cd "C:\Users\USER\Documentos\Maestr√≠a\Deep Learning\Taller2_DL_AnalisisSentimientos"

Lanza el servidor de Jupyter Notebook:
```bash
   jupyter notebook
```
Se abrir√° una ventana en tu navegador web. Dentro del navegador:
   Abre la carpeta notebooks/.

3. Ejecuta uno por uno los siguientes notebooks para entrenar cada modelo:

   02_entrenamiento_RNN.ipynb (para RNN)
   03_entrenamiento_LSTM.ipynb (para LSTM)
   04_BiLSTM_atencion.ipynb (para BiLSTM+Atenci√≥n)

Corre las celdas dentro de cada notebook manualmente (Shift + Enter).

‚úÖ Ideal si quieres ver gr√°ficas de entrenamiento y outputs en tiempo real.

#### Opci√≥n 2: Usando scripts desde Terminal (modo directo)
Si prefieres entrenar los modelos directamente desde la terminal, sin abrir Jupyter, puedes ejecutar:

```bash
--RNN python -m src.train --model rnn --epochs 5 --batch_size 128 --class_weights
--LSTM python -m src.train --model lstm --epochs 5 --batch_size 128 --class_weights
--BiLSTM+Atenci√≥n python -m src.train --model bilstm_attention --epochs 5 --batch_size 128 -class_weights
```

üìå Notas importantes:

* Los modelos entrenados se guardar√°n autom√°ticamente en la carpeta /models/.
* El tokenizer utilizado tambi√©n se guardar√° como archivo .json.
* Puedes personalizar el n√∫mero de √©pocas (--epochs), tama√±o de batch (--batch_size), balanceo (--balance) y si quieres usar pesos de clase (--class_weights).

## ‚öôÔ∏è Estrategias de Balanceo de Clases

Por defecto, **los modelos se entrenan sin aplicar t√©cnicas de balanceo de clases**.  
Esto significa que el dataset original, que presenta un fuerte desbalance (93% positivos vs 7% negativos), se utiliza tal cual para entrenar RNN, LSTM y BiLSTM+Atenci√≥n.


## üöÄ C√≥mo entrenar modelos aplicando t√©cnicas de balanceo

### 1. Entrenar con Oversampling

```bash
python -m src.train --model bilstm_attention --balance oversampling --epochs 5 --batch_size 128
python -m src.train --model lstm --balance oversampling --epochs 5 --batch_size 128
python -m src.train --model rnn --balance oversampling --epochs 5 --batch_size 128
```
### 2. Entrenar con SMOTE

```bash
python -m src.train --model bilstm_attention --balance smote --epochs 5 --batch_size 128
python -m src.train --model lstm --balance smote --epochs 5 --batch_size 128
python -m src.train --model rnn --balance smote --epochs 5 --batch_size 128
```
### 2. Entrenar con Class Weights

```bash
python -m src.train --model bilstm_attention --balance class_weights --epochs 5 --batch_size 128
python -m src.train --model lstm --balance class_weights --epochs 5 --batch_size 128
python -m src.train --model rnn --balance class_weights --epochs 5 --batch_size 128
```
## üìà Evaluaci√≥n y Predicci√≥n de Modelos

Una vez entrenados los modelos, puedes evaluarlos, comparar su rendimiento o hacer predicciones individuales de sentimientos usando el script `src/evaluate.py`.

Aseg√∫rate de estar ubicado en la carpeta ra√≠z del proyecto antes de ejecutar los siguientes comandos.

> **Nota:**  
> Los comandos de evaluaci√≥n funcionan con cualquier modelo `.h5` entrenado, ya sea sobre datos balanceados (oversampling, SMOTE, class weights) o no balanceados.  
> Aseg√∫rate de seleccionar el modelo correspondiente seg√∫n la t√©cnica que hayas utilizado en el entrenamiento.


---

### üîé Evaluar un solo modelo

Eval√∫a un modelo entrenado (`.h5`) sobre un conjunto de datos de prueba:

```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --test_size 0.2
python -m src.evaluate --model models/lstm_model.h5 --test_size 0.2
python -m src.evaluate --model models/rnn_model.h5 --test_size 0.2
```

### ü•Ω Evaluar un modelo usando un tokenizer espec√≠fico
Si deseas usar un tokenizer .json diferente al que se infiere por defecto:
```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --tokenizer models/bilstm_attention_tokenizer.json
```

### üî¨ Predecir el sentimiento de un texto personalizado
Puedes usar un modelo entrenado para predecir el sentimiento de un nuevo texto:
```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --tokenizer models/bilstm_attention_tokenizer.json --text "I love this product!"
```

### üìä Comparar varios modelos
Compara autom√°ticamente todos los modelos .h5 en la carpeta /models/, evaluando su precisi√≥n, recall, F1-score, etc.:
```bash
python -m src.evaluate --model models/bilstm_attention_model.h5 --compare
```
Nota: --model debe apuntar a un modelo ubicado dentro de la carpeta que contiene los dem√°s modelos para comparar.

## üìà Resultados

A continuaci√≥n se presentan las m√©tricas de rendimiento de cada modelo evaluado:
### Modelos con Oversampling
| Modelo          | Accuracy | Precision | Recall    | F1-Score |
|:----------------|:--------:|:---------:|:---------:|:--------:|
| BiLSTM+Atenci√≥n | 0.473330 | 0.0703    | 0.55334   | 0.1243   |
| LSTM            | 0.555764 | 0.07708   | 0.4866    | 0.1330   |
| RNN             | 0.854998 | 0.07610   | 0.0959    | 0.0848   |

### Modelos con SMOTE

| Modelo          | Accuracy | Precision | Recall    | F1-Score |
|:----------------|:--------:|:---------:|:---------:|:--------:|
| BiLSTM+Atenci√≥n | 0.637260 | 0.0686    | 0.3325    | 0.1138   |
| LSTM            | 0.778195 | 0.0971    | 0.2611    | 0.1416   |
| RNN             | 0.868606 | 0.1156    | 0.1316    | 0.1231   |

---

### üìä An√°lisis Comparativo de Modelos

El modelo RNN logr√≥ el mayor accuracy tanto con Oversampling (85.5%) como con SMOTE (86.9%). Sin embargo, su capacidad de recall (detectar casos positivos) sigue siendo baja (~9.6% y ~13.2% respectivamente), mostrando que tiende a sesgarse hacia la clase mayoritaria.

El modelo LSTM mostr√≥ un peque√±o incremento en precision y recall respecto al RNN, pero sigue teniendo dificultades para identificar correctamente la clase minoritaria, especialmente bajo Oversampling.

El modelo BiLSTM+Atenci√≥n, aunque tuvo el menor accuracy en ambos esquemas de balanceo, consigui√≥ mejorar sustancialmente el recall, particularmente bajo Oversampling (55.3%), a costa de una precisi√≥n reducida.

Insight clave: Aunque el BiLSTM+Atenci√≥n sacrifica accuracy global, logra detectar m√°s ejemplos de la clase minoritaria, lo cual es crucial en problemas altamente desbalanceados.
---

## ‚öñÔ∏è Manejo del Desbalanceo de Clases

Dado el severo desbalance inicial (29,720 negativos vs 2,242 positivos), se implementaron dos estrategias principales:

Oversampling: Duplicaci√≥n aleatoria de ejemplos de la clase minoritaria para igualar la distribuci√≥n.

SMOTE: Generaci√≥n sint√©tica de nuevos ejemplos de la clase minoritaria mediante interpolaci√≥n en el espacio de caracter√≠sticas.

Ambos m√©todos permitieron mejorar la sensibilidad de los modelos hacia la clase minoritaria, especialmente en combinaci√≥n con arquitecturas m√°s complejas como BiLSTM+Atenci√≥n.

---

## ‚ö°Ô∏è Rendimiento obtenido

RNN: Alto accuracy, pero pobre capacidad de detecci√≥n de la clase minoritaria.

LSTM: Ligera mejora en recall y F1-Score respecto a RNN, pero a√∫n insuficiente.

BiLSTM+Atenci√≥n: Mejor desempe√±o en recall y F1-Score, haciendo que sea m√°s efectivo para contextos donde detectar correctamente la clase minoritaria es prioritario.

Conclusi√≥n preliminar:
El modelo BiLSTM+Atenci√≥n, junto con t√©cnicas de balanceo como Oversampling y SMOTE, proporciona una soluci√≥n m√°s efectiva para an√°lisis de sentimientos en datasets desbalanceados.

## üß† Conclusiones

Accuracy no es suficiente como m√©trica en datasets desbalanceados. Es crucial considerar recall y F1-Score.

Modelos simples (como RNN) tienden a favorecer la clase mayoritaria.

Modelos m√°s complejos (como BiLSTM+Atenci√≥n) logran mejor balance en las m√©tricas cr√≠ticas para detecci√≥n de clases minoritarias.

T√©cnicas de balanceo como Oversampling y SMOTE son imprescindibles y mejoran significativamente el rendimiento en detecci√≥n minoritaria.

Para futuras mejoras, ser√≠a recomendable explorar t√©cnicas como:

Focal Loss para penalizar m√°s los errores en la clase minoritaria.

Data Augmentation Textual (par√°frasis, sin√≥nimos, traducciones) para enriquecer la diversidad de ejemplos positivos.

En resumen:
El uso de BiLSTM con mecanismos de atenci√≥n, combinado con estrategias de balanceo, resulta en una aproximaci√≥n m√°s robusta para enfrentar tareas de an√°lisis de sentimientos en entornos de datos desbalanceados.

## Autores del Proyecto ü§ì

Este proyecto fue desarrollado por:

* [Gers√≥n Juli√°n Rinc√≥n](https://github.com/Julk-ui) 
* [Andr√©s Bravo](https://github.com/pipebravo10)
* [Jerem√≠as Pab√≥n](https://github.com/jeremiaspabon) 
* [Carolina Tobaria](https://github.com/Carot2) 