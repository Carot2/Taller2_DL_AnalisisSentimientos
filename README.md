# An√°lisis de Sentimiento en Tweets con RNN, LSTM y BiLSTM + Atenci√≥n

Este proyecto implementa y compara diferentes arquitecturas de redes neuronales recurrentes para la clasificaci√≥n de sentimientos en tweets.


## √çndice
1. [Arquitecturas utilizadas](#arquitecturas-utilizadas)
   - [¬øQu√© es una RNN?](#qu√©-es-una-rnn)
   - [¬øQu√© es una LSTM?](#qu√©-es-una-lstm)
   - [¬øQu√© es una BiLSTM con atenci√≥n?](#qu√©-es-una-bilstm-con-atenci√≥n)
2. [Introducci√≥n a la problem√°tica](#introducci√≥n-a-la-problem√°tica)
3. [Exploraci√≥n del dataset](#exploraci√≥n-del-dataset)
   - [Descripci√≥n de las variables](#descripci√≥n-de-las-variables)
   - [An√°lisis de caracter√≠sticas y preprocesamiento](#an√°lisis-de-las-caracter√≠sticas-y-preprocesamiento-de-datos)
4. [Implementaci√≥n de la red neuronal](#implementaci√≥n-de-la-red-neuronal)
5. [Estructuraci√≥n del repositorio](#estructuraci√≥n-del-repositorio)
6. [Instrucciones de uso](#instrucciones-de-uso-de-la-red-neuronal-y-rendimiento-obtenido)
   - [Requisitos previos](#requisitos-previos)
   - [Instalaci√≥n](#instalaci√≥n)
   - [C√≥mo entrenar el modelo](#c√≥mo-entrenar-el-modelo-desde-trainpy)
   - [C√≥mo evaluar el modelo](#c√≥mo-evaluar-el-modelo-usando-evaluatepy)
   - [C√≥mo hacer predicciones](#c√≥mo-hacer-predicciones-con-predictpy)
7. [Rendimiento obtenido](#rendimiento-obtenido)
8. [Conclusiones](#conclusiones)


## ‚ö°Ô∏è Arquitecturas utilizadas

En este proyecto se implementaron y compararon tres tipos de arquitecturas de redes neuronales recurrentes para el an√°lisis de sentimientos en Tweets:

### ¬øQu√© es una RNN?

![Red Neuronal Recurrente](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/RNN.png)

Una Red Neuronal Recurrente (RNN) es un tipo de red dise√±ada para procesar secuencias de datos. A diferencia de una red neuronal tradicional, una RNN tiene una "memoria interna" que le permite recordar informaci√≥n de entradas anteriores, lo cual es √∫til en tareas como procesamiento de lenguaje natural. Sin embargo, las RNN simples suelen sufrir del problema de desvanecimiento del gradiente, lo que limita su capacidad para aprender dependencias a largo plazo.

### ¬øQu√© es una LSTM?

![Red Neuronal LSTM](https://mlarchive.com/wp-content/uploads/2024/04/New-Project-3-1-1024x607-1024x585.png)
La Long Short-Term Memory (LSTM) es una variante de la RNN dise√±ada para resolver los problemas de memoria de largo plazo. Utiliza compuertas (gate mechanisms) que controlan el flujo de informaci√≥n, permitiendo al modelo "recordar" o "olvidar" informaci√≥n seg√∫n sea necesario. Esto la hace mucho m√°s efectiva para tareas como clasificaci√≥n de sentimientos en texto.


### ¬øQu√© es una BiLSTM con atenci√≥n?

![BILSTM + ATTENTION](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/BILSTM_ATTENTION.png)

Una BiLSTM (Bidirectional LSTM) procesa la secuencia tanto hacia adelante como hacia atr√°s, capturando contexto tanto previo como posterior en una oraci√≥n. Esto mejora significativamente la comprensi√≥n sem√°ntica. Adem√°s, al a√±adir un mecanismo de **atenci√≥n**, el modelo puede aprender a enfocarse en las palabras m√°s relevantes del texto para tomar decisiones de clasificaci√≥n, mejorando la interpretaci√≥n y el rendimiento en tareas complejas como el an√°lisis de sentimiento.

## ‚ö°Ô∏è Introducci√≥n a la problem√°tica

### Aplicaciones del an√°lisis de sentimiento en redes sociales

El **an√°lisis de sentimiento** es una t√©cnica clave del procesamiento de lenguaje natural (NLP) que busca identificar y extraer opiniones, emociones o actitudes expresadas en texto. En el contexto de redes sociales como Twitter, esta t√©cnica tiene aplicaciones muy valiosas:

- **Monitoreo de la opini√≥n p√∫blica**: detectar c√≥mo reaccionan los usuarios ante eventos, marcas o personalidades.
- **Gesti√≥n de reputaci√≥n**: las empresas pueden actuar r√°pidamente ante comentarios negativos o detectar embajadores de marca.
- **Marketing dirigido**: segmentaci√≥n de usuarios seg√∫n sus actitudes o emociones.
- **Sistemas de recomendaci√≥n**: ofrecer contenido, productos o servicios personalizados en funci√≥n del sentimiento expresado.
- **An√°lisis pol√≠tico o social**: comprender el sentimiento colectivo ante decisiones pol√≠ticas o eventos sociales.

### Importancia de modelar secuencias y contexto ling√º√≠stico

A diferencia de tareas de clasificaci√≥n m√°s simples, en el an√°lisis de sentimiento **el orden de las palabras y su contexto importan enormemente**. Por ejemplo:

> *"I don't like this"* no es lo mismo que *"I like this"*

Modelos como las RNN, LSTM y BiLSTM son esenciales porque:
- Permiten modelar **dependencias temporales** entre palabras.
- Capturan **el contexto ling√º√≠stico**, incluyendo negaciones, iron√≠as o emociones impl√≠citas.
- En el caso de BiLSTM, permiten analizar un texto **en ambas direcciones** (inicio ‚Üí fin y fin ‚Üí inicio).
- El mecanismo de **atenci√≥n** mejora la capacidad del modelo para "enfocarse" en las palabras m√°s relevantes dentro del tweet.

---

## ‚ö°Ô∏è Exploraci√≥n del dataset

Para entrenar nuestros modelos, trabajamos con un conjunto de datos de tweets p√∫blicos extra√≠do de [este repositorio de GitHub](https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv). El dataset contiene **31,962 tweets en ingl√©s**, cada uno etiquetado con su **sentimiento binario**: positivo o negativo.

### **Descripci√≥n de las variables**

| Columna | Descripci√≥n |
|---------|-------------|
| `id`    | Identificador √∫nico del tweet. |
| `label` | Sentimiento asociado al tweet (`0`: negativo, `1`: positivo). |
| `tweet` | Texto completo del tweet, que puede contener menciones, hashtags, emojis, URLs y s√≠mbolos. |

se verific√≥ que el dataset **no contiene valores nulos ni duplicados**, lo que facilita el proceso de preprocesamiento y entrenamiento de modelos sin requerir limpieza adicional por valores faltantes.

--

## üìä An√°lisis de caracter√≠sticas y preprocesamiento de datos

A partir del an√°lisis exploratorio del conjunto de datos, se pueden destacar las siguientes observaciones clave:

### 1. üßÆ Desbalanceo de clases

El dataset presenta un **fuerte desbalanceo de clases**, con:

- `29,720` tweets etiquetados como **negativos**
- `2,242` tweets etiquetados como **positivos**

Esto representa una proporci√≥n de aproximadamente **13:1 a favor de la clase negativa**, como puede observarse en la siguiente gr√°fica:
![Distribuci√≥n de Tweets](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/DistribucionTweets.png)


### 2. üî† Longitud de los tweets y tokens

- El an√°lisis inicial muestra que:
  - El **95%** de los tweets negativos tiene una longitud menor o igual a **116 caracteres**
  - El **95%** de los tweets positivos no supera los **113 caracteres**

Esto justifica la elecci√≥n de una **longitud m√°xima de 120 caracteres** como l√≠mite razonable para los modelos.

Posteriormente, al **tokenizar** los textos, se observ√≥ que el **95% de los tweets contiene como m√°ximo 33 tokens**. Esta informaci√≥n se us√≥ para definir el par√°metro `max_len = 33` durante el padding, lo que permite una representaci√≥n **uniforme, eficiente y sin p√©rdida de informaci√≥n**.
![Distribuci√≥n de Tokens](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/LongTokens.png)


### 3. üßæ Palabras m√°s frecuentes por clase

Se realiz√≥ un an√°lisis de las palabras m√°s frecuentes en tweets negativos y positivos. Los resultados muestran diferencias claras en el vocabulario utilizado, lo que indica que los modelos podr√≠an aprender patrones relevantes para clasificar los tweets correctamente.

- En los tweets negativos predominan t√©rminos emocionales o expresivos como `love`, `happy`, `day`, `life`.

![PalabrasNegativas](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/NubePalabrasNegativo.png)

- En los positivos (seg√∫n etiqueta) se observan palabras relacionadas a pol√≠tica o ideolog√≠as como `trump`, `racist`, `libtard`.
![PalabrasPositivas](https://github.com/Carot2/Taller2_DL_AnalisisSentimientos/blob/main/graphics/NubePalabrasPositivo.png)

Esto puede deberse a sesgos en el dataset original, lo cual tambi√©n debe tenerse en cuenta.

---

### 4. üß™ Preprocesamiento aplicado

Para preparar los textos para el modelo, se aplicaron las siguientes transformaciones:

- Conversi√≥n a **min√∫sculas**
- Eliminaci√≥n de **menciones** (`@user`)
- Eliminaci√≥n de **hashtags**, manteniendo la palabra clave
- Remoci√≥n de **URLs**
- Eliminaci√≥n de **emojis, caracteres especiales y puntuaci√≥n**
- Reducci√≥n de **espacios m√∫ltiples**
- Tokenizaci√≥n y padding uniforme (`max_len = 33`)

---


Desde ac√° en construcci√≥n

### 5. ‚öñÔ∏è Estrategias para abordar el desbalanceo ---

Debido al fuerte desbalance, se consideraron las siguientes estrategias:

- **Oversampling**: duplicar ejemplos de la clase minoritaria para equilibrar las proporciones.
- **SMOTE**: t√©cnica de sobre-muestreo sint√©tico que genera ejemplos nuevos de la clase minoritaria.
- **Class Weights**: ponderar la p√©rdida durante el entrenamiento para penalizar m√°s los errores en la clase minoritaria.

En este proyecto, se experiment√≥ principalmente con **oversampling** y `class_weight`, dependiendo del modelo implementado.







## Estructura del Repositorio

```
mi_proyecto_sentimiento/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploracion.ipynb         # Exploraci√≥n y preprocesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ 02_entrenamiento_RNN.ipynb   # Entrenamiento y evaluaci√≥n del modelo RNN
‚îÇ   ‚îú‚îÄ‚îÄ 03_entrenamiento_LSTM.ipynb  # Entrenamiento y evaluaci√≥n del modelo LSTM
‚îÇ   ‚îî‚îÄ‚îÄ 04_BiLSTM_atencion.ipynb     # Entrenamiento y evaluaci√≥n del modelo BiLSTM+Atenci√≥n
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py               # Funciones para cargar y preprocesar los datos
‚îÇ   ‚îú‚îÄ‚îÄ model_rnn.py                 # Implementaci√≥n del modelo RNN
‚îÇ   ‚îú‚îÄ‚îÄ model_lstm.py                # Implementaci√≥n del modelo LSTM
‚îÇ   ‚îú‚îÄ‚îÄ model_bilstm_attention.py    # Implementaci√≥n del modelo BiLSTM+Atenci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ train.py                     # Funciones de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                  # Funciones de evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                     # Funciones auxiliares
‚îú‚îÄ‚îÄ models/                          # Directorio para guardar modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ rnn_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ bilstm_attention_model.h5
‚îÇ   ‚îî‚îÄ‚îÄ README.md                    # Descripci√≥n de los modelos guardados
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias del proyecto
‚îî‚îÄ‚îÄ .gitignore                       # Archivos a ignorar en Git
```

## Requisitos y Dependencias

Para ejecutar este proyecto, necesitas tener instalado Python 3.8 o superior y las siguientes bibliotecas:

```
pip install -r requirements.txt
```

## Uso

### Carga y Exploraci√≥n de Datos

El dataset se carga directamente desde una URL p√∫blica:

```python
import pandas as pd
import tensorflow as tf

url = "https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv"
csv_path = tf.keras.utils.get_file("twitter_sentiment.csv", url)
df = pd.read_csv(csv_path)
```

### Entrenamiento de Modelos

Cada modelo se puede entrenar ejecutando el notebook correspondiente:

```bash
jupyter notebook notebooks/02_entrenamiento_RNN.ipynb
jupyter notebook notebooks/03_entrenamiento_LSTM.ipynb
jupyter notebook notebooks/04_BiLSTM_atencion.ipynb
```

Tambi√©n se puede ejecutar desde la l√≠nea de comandos usando los scripts en `src/`:

```bash
python src/train.py --model rnn --epochs 5 --batch_size 128
python src/train.py --model lstm --epochs 5 --batch_size 128
python src/train.py --model bilstm_attention --epochs 5 --batch_size 128
```

### Evaluaci√≥n de Modelos

Para evaluar un modelo entrenado:

```bash
python src/evaluate.py --model models/bilstm_attention_model.h5 --test_size 0.2
```



## Resultados

A continuaci√≥n se presentan las m√©tricas de rendimiento de cada modelo:

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| RNN    | X.XX     | X.XX      | X.XX   | X.XX     |
| LSTM   | X.XX     | X.XX      | X.XX   | X.XX     |
| BiLSTM+Atenci√≥n | X.XX | X.XX  | X.XX   | X.XX     |

### An√°lisis Comparativo

(Aqu√≠ ir√° un an√°lisis comparativo de los resultados una vez entrenados los modelos)

## Manejo del Desbalanceo de Clases

Se implementaron dos estrategias para abordar el desbalanceo de clases (29720 negativos vs 2242 positivos):

1. **Oversampling**: Duplicaci√≥n aleatoria de ejemplos de la clase minoritaria.
2. **SMOTE**: Generaci√≥n de ejemplos sint√©ticos para la clase minoritaria.

Los resultados muestran que... (Esto se completar√° con los resultados de los experimentos)



## ‚ö°Ô∏è Rendimiento obtenido



## üß†Conclusiones




## Autores del Proyecto ü§ì

Este proyecto fue desarrollado por:

* [Jerem√≠as Pab√≥n](https://github.com/jeremiaspabon) 
* [Gers√≥n Juli√°n Rinc√≥n](https://github.com/Julk-ui) 
* [Andr√©s Bravo](https://github.com/pipebravo10) 
* [Carolina Tobaria](https://github.com/Carot2) 